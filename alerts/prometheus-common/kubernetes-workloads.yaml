# Source: https://samber.github.io/awesome-prometheus-alerts/rules#kubernetes-1
groups:
- name: "Kubernetes"
  rules:

  - alert: KubernetesDaemonsetRolloutStuck
    expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 < 100 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled > 0
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes DaemonSet rollout stuck
      description: "Some Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled or not ready."
      action: "Investigate and repair the affected workload, e.g. by restarting or rolling back."

  - alert: KubernetesPodCrashLooping
    expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes pod crash looping
      description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
      action: "Investigate and repair the affected pod, e.g. by restarting or rolling back."

  - alert: KubernetesContainerOomKiller
    expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 30m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[30m]) == 1
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes container OOM killed
      description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ printf \"%.2f\" $value }} times in the last 30 minutes."
      action: "Increase the memory limits for the affected containers, or spawn more containers to share the workload horizontally."

  - alert: KubernetesJobFailed
    expr: kube_job_status_failed > 0
    for: ${alert_timing_fast}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes Job failed
      description: "Job {{ $labels.namespace }}/{{ $labels.exported_job }} failed to complete"
      action: "Investigate the purpose of the failed job and repair it."

  - alert: KubernetesCronjobSuspended
    expr: kube_cronjob_spec_suspend != 0
    for: ${alert_timing_fast}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes CronJob suspended
      description: "CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is suspended"
      action: "Investigate the suspended job and either remove or enable it."

  - alert: KubernetesPersistentvolumeclaimPending
    expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes PersistentVolumeClaim pending
      description: "PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending"
      action: "Investigate the status of the PVC and resolve the issue that prevents it from creating a volume."

  - alert: KubernetesVolumeOutOfDiskSpace
    expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Volume out of disk space
      description: "PersistentVolume is almost full (< 10% left)"
      action: "Investigate whether the workload has a disk leakage problem, or increase the size of the PV."

  - alert: KubernetesPersistentvolumeError
    expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending", job="kube-state-metrics"} > 0
    for: ${alert_timing_medium}
    labels:
      severity: critical
      category: service
    annotations:
      summary: Kubernetes PersistentVolume error
      description: "PersistentVolume {{ $labels.persistentvolume }} is in bad state"
      action: "Investigate the status of the PV and resolve the underlying issue."

  - alert: KubernetesStatefulsetDown
    expr: kube_statefulset_replicas != kube_statefulset_status_replicas_ready > 0
    for: ${alert_timing_medium}
    labels:
      severity: critical
      category: service
    annotations:
      summary: Kubernetes StatefulSet down
      description: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} does not have the correct number of running replicas"
      action: "Investigate and repair the affected workload, e.g. by restarting or rolling back."

  - alert: KubernetesHpaScalingAbility
    expr: kube_horizontalpodautoscaler_status_condition{status="false", condition="AbleToScale"} == 1
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes HPA unable to scale
      description: "HPA is not able to scale a Pod"
      action: "Investigate the status of the HPA resource. Likely causes are permissions issues or not enough resources."

  - alert: KubernetesHpaMetricAvailability
    expr: kube_horizontalpodautoscaler_status_condition{status="false", condition="ScalingActive"} == 1
    for: ${alert_timing_fast}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes HPA metric availability
      description: "HPA is not able to collect metrics"
      action: "Make sure that kube-state-metrics is running in the affected cluster, or further investigate the status of the HPA resource."

  - alert: KubernetesHpaScaleCapability
    expr: kube_horizontalpodautoscaler_status_desired_replicas >= kube_horizontalpodautoscaler_spec_max_replicas
    for: ${alert_timing_medium}
    labels:
      severity: info
      category: service
    annotations:
      summary: Kubernetes HPA scale capability
      description: "HPA has reached the maximum number of desired Pods, further scaling will not be possible"
      action: "Check whether the service is still able to handle the incoming workload. If necessary, increase the maximum number of scalable pods."

  - alert: KubernetesReplicaSetMismatch
    expr: kube_replicaset_spec_replicas != kube_replicaset_status_ready_replicas
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes ReplicaSet replicas mismatch
      description: "Wrong number of replicas for ReplicaSet {{ $labels.namespace }}/{{ $labels.replicaset }}"
      action: "Investigate and repair the affected workload, e.g. by restarting or rolling back."

  - alert: KubernetesDeploymentReplicasMismatch
    expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes Deployment replicas mismatch
      description: "Wrong number of replicas for Deployment {{ $labels.namespace }}/{{ $labels.deployment }}"
      action: "Investigate and repair the affected workload, e.g. by restarting or rolling back."

  - alert: KubernetesStatefulsetReplicasMismatch
    expr: kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes StatefulSet replicas mismatch
      description: "Wrong number of replicas for StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }}"
      action: "Investigate and repair the affected workload, e.g. by restarting or rolling back."

  - alert: KubernetesDeploymentGenerationMismatch
    expr: kube_deployment_status_observed_generation != kube_deployment_metadata_generation
    for: ${alert_timing_medium}
    labels:
      severity: critical
      category: service
    annotations:
      summary: Kubernetes Deployment generation mismatch
      description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has failed but has not been rolled back."
      action: "Manually roll back to a previous version of the workload."

  - alert: KubernetesStatefulsetGenerationMismatch
    expr: kube_statefulset_status_observed_generation != kube_statefulset_metadata_generation
    for: ${alert_timing_medium}
    labels:
      severity: critical
      category: service
    annotations:
      summary: Kubernetes StatefulSet generation mismatch
      description: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has failed but has not been rolled back."
      action: "Manually roll back to a previous version of the workload."

  - alert: KubernetesStatefulsetUpdateNotRolledOut
    expr: max without (revision) (kube_statefulset_status_current_revision unless kube_statefulset_status_update_revision) * (kube_statefulset_replicas != kube_statefulset_status_replicas_updated)
    for: ${alert_timing_medium}
    labels:
      severity: warning
      category: service
    annotations:
      summary: Kubernetes StatefulSet update not rolled out
      description: "StatefulSet update has not been rolled out for {{ $labels.namespace }}/{{ $labels.statefulset }}."
      action: "Investigate the issue and either roll back or fix the cause of the stuck udpate."

  - alert: KubernetesDaemonsetMisscheduled
    expr: kube_daemonset_status_number_misscheduled > 0
    for: ${alert_timing_medium}
    labels:
      severity: critical
      category: service
    annotations:
      summary: Kubernetes DaemonSet misscheduled
      description: "Some Pods of DaemonsSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run"
      action: "Delete the excess pods."
